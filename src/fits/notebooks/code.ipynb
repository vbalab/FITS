{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "7de60f51",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "from IPython.display import clear_output\n",
    "\n",
    "\n",
    "# notebook_dir = \"/home/balabaevvl/courses/project/FITS/\"\n",
    "notebook_dir = \"/home/balabaevvl/courses/project/FITS/src/\"\n",
    "os.chdir(notebook_dir)\n",
    "\n",
    "GPUs = [\n",
    "    \"GPU-e83bd31b-fcb9-b8de-f617-2d717619413b\",\n",
    "    \"GPU-5a9b7750-9f85-49a5-3aae-fe07b1b7661d\",\n",
    "    \"GPU-fe2d8dfd-06f2-a5c4-a7fd-4a5f23947005\",\n",
    "    \"GPU-0c320096-21ee-4060-8731-826ca2febfab\",\n",
    "    \"GPU-baef952c-6609-aace-3b78-e4e07788d5de\",\n",
    "    \"GPU-3979d65b-c238-4e9c-0c1c-1aa3f05c56a1\",\n",
    "    \"GPU-6c76a2c5-5375-aa06-11d4-0fddfac30e91\",\n",
    "]\n",
    "os.environ[\"CUDA_VISIBLE_DEVICES\"] = f\"{GPUs[1]}\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "e0d30bc4",
   "metadata": {},
   "outputs": [],
   "source": [
    "from fits.data.download import DownloadDatasetAirQuality\n",
    "\n",
    "DownloadDatasetAirQuality()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "43bfcfcb",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "from fits.config import DatasetsPaths\n",
    "\n",
    "df = pd.read_csv(\n",
    "    DatasetsPaths.pm25.value,\n",
    "    index_col=\"datetime\",\n",
    "    parse_dates=True,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "dd541250",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "ForecastingData(observed_data=tensor([[138.,  89., 105.,  ...,  94., 112., 109.],\n",
       "        [124.,  85., 121.,  ..., 101., 123., 114.],\n",
       "        [127.,  88., 130.,  ..., 112., 143., 126.],\n",
       "        ...,\n",
       "        [  0.,   0.,   0.,  ...,   0.,   0.,   0.],\n",
       "        [  0.,   0.,   0.,  ...,   0.,   0.,   0.],\n",
       "        [  0.,   0.,   0.,  ...,   0.,   0.,   0.]]), observed_mask=tensor([[1., 1., 1.,  ..., 1., 1., 1.],\n",
       "        [1., 1., 1.,  ..., 1., 1., 1.],\n",
       "        [1., 1., 1.,  ..., 1., 1., 1.],\n",
       "        ...,\n",
       "        [0., 0., 0.,  ..., 0., 0., 0.],\n",
       "        [0., 0., 0.,  ..., 0., 0., 0.],\n",
       "        [0., 0., 0.,  ..., 0., 0., 0.]]), time_points=tensor([[ 0.,  0.,  0.,  ...,  0.,  0.,  0.],\n",
       "        [ 1.,  1.,  1.,  ...,  1.,  1.,  1.],\n",
       "        [ 2.,  2.,  2.,  ...,  2.,  2.,  2.],\n",
       "        ...,\n",
       "        [45., 45., 45.,  ..., 45., 45., 45.],\n",
       "        [46., 46., 46.,  ..., 46., 46., 46.],\n",
       "        [47., 47., 47.,  ..., 47., 47., 47.]]), feature_ids=tensor([[ 0.,  1.,  2.,  ..., 33., 34., 35.],\n",
       "        [ 0.,  1.,  2.,  ..., 33., 34., 35.],\n",
       "        [ 0.,  1.,  2.,  ..., 33., 34., 35.],\n",
       "        ...,\n",
       "        [ 0.,  1.,  2.,  ..., 33., 34., 35.],\n",
       "        [ 0.,  1.,  2.,  ..., 33., 34., 35.],\n",
       "        [ 0.,  1.,  2.,  ..., 33., 34., 35.]]))"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from fits.data.dataset import ModelMode, DatasetAirQuality\n",
    "\n",
    "dataset = DatasetAirQuality(ModelMode.train)\n",
    "\n",
    "for sample in dataset:\n",
    "    break\n",
    "\n",
    "sample"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "f4e2d0bd",
   "metadata": {},
   "outputs": [
    {
     "ename": "ValueError",
     "evalue": "__len__() should return >= 0",
     "output_type": "error",
     "traceback": [
      "\u001b[31m---------------------------------------------------------------------------\u001b[39m",
      "\u001b[31mValueError\u001b[39m                                Traceback (most recent call last)",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[4]\u001b[39m\u001b[32m, line 4\u001b[39m\n\u001b[32m      1\u001b[39m \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34;01mfits\u001b[39;00m\u001b[34;01m.\u001b[39;00m\u001b[34;01mdata\u001b[39;00m\u001b[34;01m.\u001b[39;00m\u001b[34;01mdataloader\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mimport\u001b[39;00m ForecastingDataLoader\n\u001b[32m      2\u001b[39m \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34;01mfits\u001b[39;00m\u001b[34;01m.\u001b[39;00m\u001b[34;01mdata\u001b[39;00m\u001b[34;01m.\u001b[39;00m\u001b[34;01mdataset\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mimport\u001b[39;00m DatasetAirQuality\n\u001b[32m----> \u001b[39m\u001b[32m4\u001b[39m train_loader, valid_loader, test_loader = \u001b[43mForecastingDataLoader\u001b[49m\u001b[43m(\u001b[49m\u001b[43mDatasetAirQuality\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mbatch_size\u001b[49m\u001b[43m=\u001b[49m\u001b[32;43m128\u001b[39;49m\u001b[43m)\u001b[49m\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/courses/project/FITS/src/fits/data/dataloader.py:29\u001b[39m, in \u001b[36mForecastingDataLoader\u001b[39m\u001b[34m(dataset_cls, batch_size, num_workers, **dataset_kwargs)\u001b[39m\n\u001b[32m     20\u001b[39m test_ds = dataset_cls(mode=ModelMode.test, **dataset_kwargs)\n\u001b[32m     22\u001b[39m train_loader = DataLoader(\n\u001b[32m     23\u001b[39m     train_ds,\n\u001b[32m     24\u001b[39m     batch_size=batch_size,\n\u001b[32m     25\u001b[39m     num_workers=num_workers,\n\u001b[32m     26\u001b[39m     shuffle=\u001b[38;5;28;01mTrue\u001b[39;00m,\n\u001b[32m     27\u001b[39m )\n\u001b[32m---> \u001b[39m\u001b[32m29\u001b[39m valid_loader = \u001b[43mDataLoader\u001b[49m\u001b[43m(\u001b[49m\n\u001b[32m     30\u001b[39m \u001b[43m    \u001b[49m\u001b[43mvalid_ds\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m     31\u001b[39m \u001b[43m    \u001b[49m\u001b[43mbatch_size\u001b[49m\u001b[43m=\u001b[49m\u001b[43mbatch_size\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m     32\u001b[39m \u001b[43m    \u001b[49m\u001b[43mnum_workers\u001b[49m\u001b[43m=\u001b[49m\u001b[43mnum_workers\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m     33\u001b[39m \u001b[43m    \u001b[49m\u001b[43mshuffle\u001b[49m\u001b[43m=\u001b[49m\u001b[38;5;28;43;01mTrue\u001b[39;49;00m\u001b[43m,\u001b[49m\n\u001b[32m     34\u001b[39m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m     36\u001b[39m test_loader = DataLoader(\n\u001b[32m     37\u001b[39m     test_ds,\n\u001b[32m     38\u001b[39m     batch_size=batch_size,\n\u001b[32m     39\u001b[39m     num_workers=num_workers,\n\u001b[32m     40\u001b[39m     shuffle=\u001b[38;5;28;01mFalse\u001b[39;00m,  \u001b[38;5;66;03m#!\u001b[39;00m\n\u001b[32m     41\u001b[39m )\n\u001b[32m     43\u001b[39m \u001b[38;5;28;01mreturn\u001b[39;00m train_loader, valid_loader, test_loader\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/courses/venv311/lib/python3.11/site-packages/torch/utils/data/dataloader.py:388\u001b[39m, in \u001b[36mDataLoader.__init__\u001b[39m\u001b[34m(self, dataset, batch_size, shuffle, sampler, batch_sampler, num_workers, collate_fn, pin_memory, drop_last, timeout, worker_init_fn, multiprocessing_context, generator, prefetch_factor, persistent_workers, pin_memory_device, in_order)\u001b[39m\n\u001b[32m    386\u001b[39m \u001b[38;5;28;01melse\u001b[39;00m:  \u001b[38;5;66;03m# map-style\u001b[39;00m\n\u001b[32m    387\u001b[39m     \u001b[38;5;28;01mif\u001b[39;00m shuffle:\n\u001b[32m--> \u001b[39m\u001b[32m388\u001b[39m         sampler = \u001b[43mRandomSampler\u001b[49m\u001b[43m(\u001b[49m\u001b[43mdataset\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mgenerator\u001b[49m\u001b[43m=\u001b[49m\u001b[43mgenerator\u001b[49m\u001b[43m)\u001b[49m  \u001b[38;5;66;03m# type: ignore[arg-type]\u001b[39;00m\n\u001b[32m    389\u001b[39m     \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[32m    390\u001b[39m         sampler = SequentialSampler(dataset)  \u001b[38;5;66;03m# type: ignore[arg-type]\u001b[39;00m\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/courses/venv311/lib/python3.11/site-packages/torch/utils/data/sampler.py:161\u001b[39m, in \u001b[36mRandomSampler.__init__\u001b[39m\u001b[34m(self, data_source, replacement, num_samples, generator)\u001b[39m\n\u001b[32m    156\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(\u001b[38;5;28mself\u001b[39m.replacement, \u001b[38;5;28mbool\u001b[39m):\n\u001b[32m    157\u001b[39m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mTypeError\u001b[39;00m(\n\u001b[32m    158\u001b[39m         \u001b[33mf\u001b[39m\u001b[33m\"\u001b[39m\u001b[33mreplacement should be a boolean value, but got replacement=\u001b[39m\u001b[38;5;132;01m{\u001b[39;00m\u001b[38;5;28mself\u001b[39m.replacement\u001b[38;5;132;01m}\u001b[39;00m\u001b[33m\"\u001b[39m\n\u001b[32m    159\u001b[39m     )\n\u001b[32m--> \u001b[39m\u001b[32m161\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43mnum_samples\u001b[49m, \u001b[38;5;28mint\u001b[39m) \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m.num_samples <= \u001b[32m0\u001b[39m:\n\u001b[32m    162\u001b[39m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(\n\u001b[32m    163\u001b[39m         \u001b[33mf\u001b[39m\u001b[33m\"\u001b[39m\u001b[33mnum_samples should be a positive integer value, but got num_samples=\u001b[39m\u001b[38;5;132;01m{\u001b[39;00m\u001b[38;5;28mself\u001b[39m.num_samples\u001b[38;5;132;01m}\u001b[39;00m\u001b[33m\"\u001b[39m\n\u001b[32m    164\u001b[39m     )\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/courses/venv311/lib/python3.11/site-packages/torch/utils/data/sampler.py:170\u001b[39m, in \u001b[36mRandomSampler.num_samples\u001b[39m\u001b[34m(self)\u001b[39m\n\u001b[32m    166\u001b[39m \u001b[38;5;129m@property\u001b[39m\n\u001b[32m    167\u001b[39m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34mnum_samples\u001b[39m(\u001b[38;5;28mself\u001b[39m) -> \u001b[38;5;28mint\u001b[39m:\n\u001b[32m    168\u001b[39m     \u001b[38;5;66;03m# dataset size might change at runtime\u001b[39;00m\n\u001b[32m    169\u001b[39m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m._num_samples \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[32m--> \u001b[39m\u001b[32m170\u001b[39m         \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mlen\u001b[39;49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43mdata_source\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    171\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m._num_samples\n",
      "\u001b[31mValueError\u001b[39m: __len__() should return >= 0"
     ]
    }
   ],
   "source": [
    "from fits.data.dataloader import ForecastingDataLoader\n",
    "from fits.data.dataset import DatasetAirQuality\n",
    "\n",
    "train_loader, valid_loader, test_loader = ForecastingDataLoader(\n",
    "    DatasetAirQuality, batch_size=128\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "c028c414",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/balabaevvl/courses/venv311/lib/python3.11/site-packages/torch/nn/modules/transformer.py:392: UserWarning: enable_nested_tensor is True, but self.use_nested_tensor is False because encoder_layer.self_attn.batch_first was not True(use batch_first for better inference performance)\n",
      "  warnings.warn(\n"
     ]
    }
   ],
   "source": [
    "from fits.modelling.framework import Train\n",
    "from fits.modelling.CSDI.adapter import CSDIAdapter\n",
    "\n",
    "csdi = CSDIAdapter()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9c89fd3c",
   "metadata": {},
   "outputs": [],
   "source": [
    "Train()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "22a9594d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# TODO: data normalization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9eb28f22",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
